{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o arquivo usando o método do professor para arquivos desorganizados\n",
    "from google.colab import files\n",
    "\n",
    "# Remove todos os arquivos temporários enviados anteriormente\n",
    "!rm -rf /content/*\n",
    "\n",
    "# Fazer upload do arquivo\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo SMSSpamCollection com tabulação como separador\n",
    "df = pd.read_csv(io.BytesIO(uploaded['SMSSpamCollection']), sep='\\t', header=None, names=['target', 'text'])\n",
    "\n",
    "# Verificar a leitura correta\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeando a variável target\n",
    "df['target'] = df['target'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Separando X (textos) e y (target)\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "# Verificando o balanceamento percentual da base de dados\n",
    "class_counts = y.value_counts(normalize=True) * 100\n",
    "print(\"Distribuição das classes (em %):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Aplicando TfidfVectorizer apenas no conjunto de treino\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transformando o conjunto de teste com o vocabulário do treino\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo de Regressão Logística\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Previsão e probabilidade\n",
    "y_pred_lr = model_lr.predict(X_test_tfidf)\n",
    "y_pred_prob_lr = model_lr.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Cálculo das métricas\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, y_pred_prob_lr)\n",
    "pr_auc_lr = average_precision_score(y_test, y_pred_prob_lr)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(f\"Acurácia: {accuracy_lr:.4f}\")\n",
    "print(f\"Precisão: {precision_lr:.4f}\")\n",
    "print(f\"Recall: {recall_lr:.4f}\")\n",
    "print(f\"F1-Score: {f1_lr:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_lr:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_lr:.4f}\")\n",
    "\n",
    "# Histogramas\n",
    "thresholds = [0.05, 0.75]\n",
    "bins = np.linspace(0, 1, 11)\n",
    "counts_general, _ = np.histogram(y_pred_prob_lr, bins=bins)\n",
    "counts_spam, _ = np.histogram(y_pred_prob_lr[y_test == 1], bins=bins)\n",
    "percentages_general = counts_general / counts_general.sum() * 100\n",
    "percentages_spam = counts_spam / counts_spam.sum() * 100\n",
    "bar_width = 0.4\n",
    "bar_positions = np.arange(len(bins) - 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma de Probabilidades\n",
    "plt.bar(bar_positions - bar_width/2, percentages_general, width=bar_width, color='blue', label='População Geral', alpha=0.7, edgecolor='black')\n",
    "plt.bar(bar_positions + bar_width/2, percentages_spam, width=bar_width, color='red', label='Spam', alpha=0.7, edgecolor='black')\n",
    "plt.axvline(thresholds[0] * (len(bins) - 1), color='green', linestyle='--', label=f'< {int(thresholds[0] * 100)}% Spam')\n",
    "plt.axvline(thresholds[1] * (len(bins) - 1), color='green', linestyle='--', label=f'> {int(thresholds[1] * 100)}% Spam')\n",
    "plt.title('Logistic Regression - Distribuição das Probabilidades Preditas')\n",
    "plt.xlabel('Probabilidade de ser spam')\n",
    "plt.ylabel('Percentual da População')\n",
    "plt.xticks(bar_positions, labels=[f'{int(b * 100)}%' for b in bins[:-1]])\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "\n",
    "# Curvas ROC e PR\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_lr)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='blue', label=f'Logistic Regression (AUC = {roc_auc_lr:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "\n",
    "# Curva PR\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob_lr)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', label=f'Logistic Regression (AUC = {pr_auc_lr:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisão')\n",
    "plt.title('Curva Precision-Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o modelo Random Forest\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "model_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Previsão e probabilidade\n",
    "y_pred_rf = model_rf.predict(X_test_tfidf)\n",
    "y_pred_prob_rf = model_rf.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Cálculo das métricas\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_prob_rf)\n",
    "pr_auc_rf = average_precision_score(y_test, y_pred_prob_rf)\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(f\"Acurácia: {accuracy_rf:.4f}\")\n",
    "print(f\"Precisão: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1-Score: {f1_rf:.4f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_rf:.4f}\")\n",
    "print(f\"AUC-PR: {pr_auc_rf:.4f}\")\n",
    "\n",
    "# Histogramas\n",
    "thresholds = [0.05, 0.65]\n",
    "bins = np.linspace(0, 1, 11)\n",
    "counts_general, _ = np.histogram(y_pred_prob_rf, bins=bins)\n",
    "counts_spam, _ = np.histogram(y_pred_prob_rf[y_test == 1], bins=bins)\n",
    "percentages_general = counts_general / counts_general.sum() * 100\n",
    "percentages_spam = counts_spam / counts_spam.sum() * 100\n",
    "bar_width = 0.4\n",
    "bar_positions = np.arange(len(bins) - 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma de Probabilidades\n",
    "plt.bar(bar_positions - bar_width/2, percentages_general, width=bar_width, color='blue', label='População Geral', alpha=0.7, edgecolor='black')\n",
    "plt.bar(bar_positions + bar_width/2, percentages_spam, width=bar_width, color='red', label='Spam', alpha=0.7, edgecolor='black')\n",
    "plt.axvline(thresholds[0] * (len(bins) - 1), color='green', linestyle='--', label=f'< {int(thresholds[0] * 100)}% Spam')\n",
    "plt.axvline(thresholds[1] * (len(bins) - 1), color='green', linestyle='--', label=f'> {int(thresholds[1] * 100)}% Spam')\n",
    "plt.title('Random Forest - Distribuição das Probabilidades Preditas')\n",
    "plt.xlabel('Probabilidade de ser spam')\n",
    "plt.ylabel('Percentual da População')\n",
    "plt.xticks(bar_positions, labels=[f'{int(b * 100)}%' for b in bins[:-1]])\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()\n",
    "\n",
    "# Curvas ROC e PR\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob_rf)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='blue', label=f'Random Forest (AUC = {roc_auc_rf:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "\n",
    "# Curva PR\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob_rf)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', label=f'Random Forest (AUC = {pr_auc_rf:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisão')\n",
    "plt.title('Curva Precision-Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
